# HateSpeechDetection

This project detects hate speech in texts, using a dataset of more than 2,000 tweets labeled as hate speech, offensive, or neither. It applies three ML approaches: Random Forest, XGBoost, and a Neural Network. The project is a prototype that demonstrates how different models interpret human language and compares their performance. Detecting hate speech is an important step in protecting minorities and vulnerable people from harassment, making this project socially relevant. Additionally, comparing different ML models presents many challenges, and this project does not address all the nuances; therefore, I do not claim that any model is definitively superior to the others in detecting hate speech

##summary

**Project Goal:** Detect hate speech in social media texts.   

**Dataset:** More than 2,000 tweets labeled as hate speech, offensive, or neither. Methods Used:   

• Random Forest   

• XGBoost   

• Neural Network   

**Process:** Includes text preprocessing and model training.   

**Purpose:** Prototype to demonstrate how ML models interpret human language.   

**Social Relevance:** Helps protect minorities and vulnerable groups from online harassment.   

**Model Comparison:** Evaluates performance differences between models, but Challenges in definitively determining the most effective model; nuanced results not fully addressed.   

